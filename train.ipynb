{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034d33f1",
   "metadata": {},
   "source": [
    "### Training a basic segmentation algorithm in Pytorch Lightning\n",
    "\n",
    "In this python notebook, I will outline a barebones Pytorch Lightning (PL) implementation of training a network for the CAMUS echocardiography segmentation challenge.\n",
    "\n",
    "Pytorch Lightning is a library that is completely built on Pytorch, but it re-organizes pytorch code into something more concise and readable.\n",
    "\n",
    "Just like in Pytorch, PL starts with defining an architecture as a class-object. In addition, we must also define a training and validation step as a class-function -- such that later we can simply call trainer.fit(). PL has scripted the rest for us, which spares us a lot of boiler-plate coding.\n",
    "\n",
    "So, we define a model as follows, note that we inherit the pl.LightningModule base class intead of torch.nn.Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dd9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import monai\n",
    "\n",
    "# define the LightningModule\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, out_path_test='./test_results/'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = monai.networks.nets.UNet(\n",
    "                                        spatial_dims=2,\n",
    "                                        in_channels=1,\n",
    "                                        out_channels=4,\n",
    "                                        channels=(16, 32, 64, 128, 256),\n",
    "                                        strides=(2, 2, 2, 2),\n",
    "                                        num_res_units=2,\n",
    "                                        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.out_path_test = out_path_test\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x) #self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        # Logging (to TensorBoard  by default)\n",
    "        self.log(\"loss\", {'train': loss.item() } )\n",
    "        return loss  \n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"loss\", {'val': loss })\n",
    "        return loss    \n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def predict_step(self, sample, sample_idx):\n",
    "        x, y = sample  # INCOMPATIBLE WITH batch_size > 1\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        # log results as images\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(16,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('ground truth', fontsize=30)\n",
    "        ax2.set_title('image', fontsize=30)\n",
    "\n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(y[0].cpu(),  vmax=3); ax1.axis('off')\n",
    "        ax2.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax2.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('inference results', fig, sample_idx)\n",
    "        \n",
    "        \n",
    "    def test_step(self, sample, sample_idx):\n",
    "        x, x_attrs, info = sample # INCOMPATIBLE WITH batch_size > 1\n",
    "        \n",
    "        # pad until divisible by 2^n (because of n up- and downsampling steps):\n",
    "        two_n = 16\n",
    "        row_pad = (-x.shape[-2]) % two_n\n",
    "        col_pad = (-x.shape[-1]) % two_n\n",
    "        x_padded = F.pad(x, (col_pad, 0, row_pad, 0))\n",
    "        \n",
    "        y_hat = self.forward(x_padded)[:, :, row_pad:, col_pad:]\n",
    "\n",
    "        \n",
    "        # log results to Tensorboard:\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(11,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('image', fontsize=30)\n",
    "        \n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax1.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('test results', fig, sample_idx)\n",
    "        \n",
    "        # write output to mhd+raw files (but first convert to sitk):\n",
    "        mask = TF.resize(y_hat, x_attrs['shape'], InterpolationMode.BICUBIC)\n",
    "        mask = mask.argmax(dim=1, keepdim=True).type(torch.uint8)[0]\n",
    "        \n",
    "        mask_sitk = sitk.GetImageFromArray(mask.cpu().numpy())\n",
    "        mask_sitk.SetSpacing([x.item() for x in x_attrs['spacing']])\n",
    "\n",
    "        filename = \"_\".join(x[0] for x in info[:3]) + '.mhd'\n",
    "        out_path = os.path.join(self.out_path_test, filename)\n",
    "\n",
    "        writer = sitk.ImageFileWriter()\n",
    "        writer.SetFileName(out_path)\n",
    "        writer.Execute(mask_sitk)\n",
    "        \n",
    "                   \n",
    "# init the model\n",
    "model = SegmentationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4aa552",
   "metadata": {},
   "source": [
    "As a next step, we need to define a dataset class. This is one is identical to a pytorch dataset object: we simply define how we want to load our data samples, and make them retrievable by defining indices. \n",
    "\n",
    "To organize the data, I recurse through the dataset directories, and put the relevant info in a Pandas dataframe (df). Every row in the df represents one image, and calling their row index will retrieve the image and mask data with the __getitem__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb0f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "class CamusDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file.split('_')[-1] == 'gt.mhd':\n",
    "                    sample = file.split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        aspect_ratio = spacing[1]/spacing[0]\n",
    "        \n",
    "        # convert to numpy\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(f'{path}_gt.mhd', sitk.sitkFloat32))\n",
    "        \n",
    "        # compute aspect ratio of pixel(mm) and image(pixels)\n",
    "        pixel_aspect = spacing[1] / spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image and mask\n",
    "        image, mask = torch.Tensor(image), torch.Tensor(mask)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        mask = resize(mask, size, interpolation=InterpolationMode.NEAREST)\n",
    "        \n",
    "        image, mask = center_crop(image, self.image_size), center_crop(mask, self.image_size)\n",
    "        mask = mask.squeeze()\n",
    "\n",
    "        return image, mask.to(torch.long)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ffcc8",
   "metadata": {},
   "source": [
    "Now we instantiate the dataset object, and split the data into a training and validation set.\n",
    "The dataloaders control how the data will be batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8523b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# init dataset object\n",
    "dataset = CamusDataset(data_path=r\"C:\\Users\\Gino\\datasets\\CAMUS\\training\", image_size=(512, 512))\n",
    "\n",
    "# split into train and validation set, by splitting indices:\n",
    "train_indices = list(range(1600))\n",
    "val_indices = list(range(1600, len(dataset)))\n",
    "\n",
    "# init samplers: \n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# init loaders: (set num_workers to 8 * number of gpus, 0 for debugging)\n",
    "train_loader = utils.data.DataLoader(dataset, sampler=train_sampler, batch_size=5, num_workers=0)\n",
    "val_loader = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453861b3",
   "metadata": {},
   "source": [
    "Finally, we define a trainer, which takes care of the rest. We train by simply calling trainer.fit(): \n",
    "\n",
    "Run ```tensorboard --logdir=lightning_logs --samples_per_plugin images=200``` in your (anaconda/bash) terminal to track the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802f6989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | UNet             | 1.6 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.503     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8541192a592140baa92d52b7cbb88d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model:\n",
    "trainer = pl.Trainer(max_epochs=20, gpus=1)#, limit_train_batches=10)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6372b7f",
   "metadata": {},
   "source": [
    "Let's display some (validation) results in Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88a17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1386: UserWarning: `.predict(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.predict(ckpt_path='best')` to use the best model or `.predict(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at C:\\Users\\Gino\\CamusPytorch\\lightning_logs\\version_31\\checkpoints\\epoch=19-step=6400.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at C:\\Users\\Gino\\CamusPytorch\\lightning_logs\\version_31\\checkpoints\\epoch=19-step=6400.ckpt\n",
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1176a68a2441039e21d426718df533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 320it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py:135: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
      "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"
     ]
    }
   ],
   "source": [
    "# automatically auto-loads the best weights from the previous run\n",
    "val_loader_log = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=1, num_workers=0)\n",
    "outputs = trainer.predict(dataloaders=val_loader_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45d782",
   "metadata": {},
   "source": [
    "Finally, if we're happy with the results, we should run our network on the test set, and save the resulting masks in a format that's compatible with the CAMUS challenge website (The website allows 4 test submissions).\n",
    "\n",
    "\n",
    "First we need to adjust the dataset class, as the ```__getitem__``` method shouldn't try to load a ground truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89393bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamusTestSet(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                suffix = file.split('_')[-1]\n",
    "                if suffix in ['ED.mhd', 'ES.mhd']:\n",
    "                    sample = file.split('.')[0].split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        \n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        pixel_aspect = spacing[1]/spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image\n",
    "        image = torch.Tensor(image)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        \n",
    "        image_attrs = dict(\n",
    "            shape = [image_sitk.GetHeight(), image_sitk.GetWidth()],\n",
    "            spacing = spacing\n",
    "        )\n",
    "        return image, image_attrs, row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99cf2",
   "metadata": {},
   "source": [
    "Now we are ready to test the model. Earlier, in the model Class definition, I defined the ```test_step```, where it writes a predicted mask to an .mhd file format, which is compatible with the Challenge submission website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cda19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at C:\\Users\\Gino\\CamusPytorch\\lightning_logs\\version_31\\checkpoints\\epoch=19-step=6400.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at C:\\Users\\Gino\\CamusPytorch\\lightning_logs\\version_31\\checkpoints\\epoch=19-step=6400.ckpt\n",
      "C:\\Users\\Gino\\anaconda3\\envs\\lightning\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15230400fac746c3ba180eb86e863458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = CamusTestSet(data_path=r\"C:\\Users\\Gino\\datasets\\CAMUS\\testing\")\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=1, num_workers=0)\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04a550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
